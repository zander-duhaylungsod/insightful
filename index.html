<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Object Detection for Blind Users</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            text-align: center;
            background-color: #f4f4f4;
            margin: 0;
            padding: 0;
            overflow: hidden;
        }
        video {
            width: 100%;
            height: 100%;
            object-fit: cover;
        }
    </style>
</head>
<body>
    <video id="camera-stream" autoplay playsinline></video>
    
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs"></script>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/coco-ssd"></script>

    <script>
        let detectedObjects = [];
        let usingFrontCamera = false;  // Track whether front or back camera is being used
        let stream = null;

        // Function to access the camera
        function startCamera(facingMode) {
            // If there's an existing stream, stop it before switching
            if (stream) {
                stream.getTracks().forEach(track => track.stop());
            }

            // Request the camera stream with the desired facing mode
            navigator.mediaDevices.getUserMedia({ video: { facingMode: facingMode } })
                .then((mediaStream) => {
                    stream = mediaStream;
                    document.getElementById('camera-stream').srcObject = mediaStream;
                })
                .catch((error) => {
                    console.error('Error accessing the camera:', error);
                });
        }

        // Function to toggle between front and back cameras
        function toggleCamera() {
            usingFrontCamera = !usingFrontCamera;
            const facingMode = usingFrontCamera ? 'user' : 'environment';  // 'user' for front cam, 'environment' for back cam
            startCamera(facingMode);
        }

        // Load the TensorFlow model and detect objects
        cocoSsd.load().then(model => {
            // Capture objects from the video stream every second
            setInterval(() => {
                model.detect(document.getElementById('camera-stream')).then(predictions => {
                    detectedObjects = predictions;  // Store the detected objects
                });
            }, 1000);  // Check for objects every second
        });

        // Function to read out the detected object
        function readObjectAloud(text) {
            const speech = new SpeechSynthesisUtterance(text);
            window.speechSynthesis.speak(speech);
        }

        // Handle screen taps or clicks to voice out the detected object
        document.body.addEventListener('click', () => {
            if (detectedObjects.length > 0) {
                const objectName = detectedObjects[0].class;  // Read the first detected object
                readObjectAloud(objectName);
            } else {
                readObjectAloud("No object detected");
            }
        });

        // Handle double-tap or double-click to switch cameras
        let lastTap = 0;
        document.body.addEventListener('dblclick', () => {
            const currentTime = new Date().getTime();
            const tapLength = currentTime - lastTap;
            
            if (tapLength < 500 && tapLength > 0) {
                toggleCamera();  // Switch the camera on double tap
            }
            lastTap = currentTime;
        });

        // Start with the back camera by default
        startCamera('environment');
    </script>
</body>
</html>
